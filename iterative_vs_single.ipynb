{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. single approach that predicts N edges using max_balance in one run\n",
    "# and then predict using lowrank method\n",
    "\n",
    "# 2. iterative approach that predicts N edges in X runs\n",
    "# and then predict using LR method\n",
    "\n",
    "\n",
    "# result:\n",
    "# plot of two lines: \n",
    "# x-axis: N, minimum triangle count threshold (similar to embeddedness)\n",
    "# y-axis: accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import _pickle as pkl\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "from snpp.cores.lowrank import alq_spark, predict_signs\n",
    "from snpp.utils.matrix import split_train_test, load_sparse_csr\n",
    "from snpp.utils.signed_graph import g2m\n",
    "from snpp.utils.data import load_train_test_graphs\n",
    "from snpp.utils.edge_filter import filter_by_min_triangle_count\n",
    "\n",
    "from snpp.utils.spark import sc\n",
    "\n",
    "dataset = 'slashdot'\n",
    "lambda_ = 0.2\n",
    "k = 5\n",
    "max_iter = 100\n",
    "random_seed = 123456\n",
    "min_tri_count = 20\n",
    "\n",
    "recache_input = False\n",
    "\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train and test graphs...\n"
     ]
    }
   ],
   "source": [
    "train_g, test_g = load_train_test_graphs(dataset, recache_input)\n",
    "train_g_ud = train_g.to_undirected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "confident_edges = set(filter_by_min_triangle_count(train_g_ud, test_g.edges(), min_tri_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 233/2645 [00:00<00:01, 2325.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build edge2edges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2645/2645 [00:01<00:00, 2256.54it/s]\n"
     ]
    }
   ],
   "source": [
    "from snpp.cores.joint_part_pred import iterative_approach\n",
    "from snpp.cores.max_balance import faster_greedy\n",
    "from snpp.cores.lowrank import partition_graph\n",
    "from snpp.cores.budget_allocation import constant_budget\n",
    "from snpp.cores.triangle import build_edge2edges\n",
    "\n",
    "common_params = dict(\n",
    "    g=train_g_ud,\n",
    "    T=confident_edges,\n",
    "    k=k,\n",
    "    graph_partition_f=partition_graph,\n",
    "    graph_partition_kwargs=dict(sc=sc,\n",
    "                                lambda_=lambda_,\n",
    "                                iterations=max_iter,\n",
    "                                seed=random_seed),\n",
    "    budget_allocation_f=constant_budget,\n",
    "    solve_maxbalance_f=faster_greedy,\n",
    "    solve_maxbalance_kwargs={'edge2edges': build_edge2edges(train_g_ud.copy(),\n",
    "                                                            confident_edges)},\n",
    "    truth=set([(i, j, test_g[i][j]['sign'])\n",
    "               for i, j in confident_edges]),\n",
    "    perform_last_partition=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snpp.utils.evaluation import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# single iteration approach\n",
    "\n",
    "part, single_preds, status = iterative_approach(\n",
    "    budget_allocation_kwargs=dict(const=len(confident_edges)),\n",
    "    **common_params\n",
    ")\n",
    "print(\" => accuracy {} (single)\".format(accuracy(test_g, single_preds)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# iterative approach\n",
    "\n",
    "part, iter_preds, status = iterative_approach(\n",
    "    budget_allocation_kwargs=dict(const=200),\n",
    "    **common_params\n",
    ")\n",
    "print(\" => accuracy {} (iterative)\".format(accuracy(test_g, iter_preds)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to_scipy_sparse_matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77357/77357 [00:01<00:00, 52765.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS...\n",
      "predict labels (SVD + Kmeans)...\n",
      "eigen values: [ 190.59474185   90.81402874   70.1883324    47.81850672   35.17200069\n",
      "   32.65883398   28.2857246    26.76476412   26.15166153   25.78369751\n",
      "   25.28476371   24.56391419   24.03171128   22.94467161   22.06543332\n",
      "   21.10618394   20.655356     20.19932586   19.36947917   19.19516865\n",
      "   18.77874012   17.8812066    17.3571094    16.76504895   16.20612479\n",
      "   14.92819051   14.42525262   13.9064831    13.53853552   13.20960812\n",
      "   12.24701639   11.67489415   11.06718951   10.64686697   10.48079306\n",
      "   10.09816838    9.45630068    9.06644391    8.75918222    8.48775764]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cloud-user/code/snpp/venv/lib/python3.5/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/cloud-user/code/snpp/venv/lib/python3.5/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/cloud-user/code/snpp/venv/lib/python3.5/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/cloud-user/code/snpp/venv/lib/python3.5/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/cloud-user/code/snpp/venv/lib/python3.5/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/cloud-user/code/snpp/venv/lib/python3.5/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/cloud-user/code/snpp/venv/lib/python3.5/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/home/cloud-user/code/snpp/venv/lib/python3.5/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    }
   ],
   "source": [
    "# partition and cut approach\n",
    "\n",
    "from snpp.cores.joint_part_pred import single_run_approach\n",
    "\n",
    "_, part_and_cut_preds = single_run_approach(train_g_ud, \n",
    "                                            confident_edges,\n",
    "                                            k,\n",
    "                                            graph_partition_f=partition_graph,\n",
    "                                            graph_partition_kwargs=dict(sc=sc,\n",
    "                                                                    lambda_=lambda_,\n",
    "                                                                    iterations=max_iter,\n",
    "                                                                    seed=random_seed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " => accuracy 0.6170132325141777 (partition-and-cut)\n"
     ]
    }
   ],
   "source": [
    "print(\" => accuracy {} (partition-and-cut)\".format(accuracy(test_g, part_and_cut_preds)))\n",
    "\n",
    "# k=5   => accuracy 0.6170132325141777 (partition-and-cut)\n",
    "# k=10 => accuracy 0.71\n",
    "# k=40 => accuracy 0.5024574669187145 (partition-and-cut)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
